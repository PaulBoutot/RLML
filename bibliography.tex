\usepackage{url}
\UseRawInputEncoding
\usepackage[utf8]{inputenc}

@article{meacham2020,
    author={Meacham,Sofia and Pech,Vaclav and Nauck,Detlef},
    year={2020},
    title={Classification Algorithms Framework (CAF) to Enable Intelligent Systems Using JetBrains MPS Domain-Specific Languages Environment},
    journal={IEEE access},
    volume={8},
    pages={14832-14840},
    abstract={This paper describes the design and development of a Classification Algorithms Framework (CAF) using the JetBrains MPS domain-specific languages (DSLs) development environment. It is increasingly recognized that the systems of the future will contain some form of adaptivity therefore making them intelligent systems as opposed to the static systems of the past. These intelligent systems can be extremely complex and difficult to maintain. Descriptions at higher-level of abstraction (system-level) have long been identified by industry and academia to reduce complexity. This research presents a Framework of Classification Algorithms at system-level that enables quick experimentation with several different algorithms from Naive Bayes to Logistic Regression. It has been developed as a tool to address the requirements of British Telecom's (BT's) data-science team. The tool has been presented at BT and JetBrains MPS and feedback has been collected and evaluated. Beyond the reduction in complexity through the system-level description, the most prominent advantage of this research is its potential applicability to many application contexts. It has been designed to be applicable for intelligent applications in several domains from business analytics, eLearning to eHealth, etc. Its wide applicability will contribute to enabling the larger vision of Artificial Intelligence (AI) adoption in context.},
    keywords={Classification algorithms; domain-specific languages; DSL; framework; Intelligent systems; Libraries; Software algorithms; Tools},
    isbn={2169-3536},
    language={English}
}

@article{Bucchiarone2020,
author = {Bucchiarone, Antonio and Cabot, Jordi and Paige, Richard and Pierantonio, Alfonso},
year = {2020},
month = {01},
pages = {1-9},
title = {Grand challenges in model-driven engineering: an analysis of the state of the research},
volume = {19},
journal = {Software and Systems Modeling},
doi = {10.1007/s10270-019-00773-6}
}

@article{Brunton2019,
author = {Brunton, Steven and Kutz, J.},
year = {2019},
month = {02},
pages = {ix-xii},
title = {Data-Driven Science and Engineering},
doi = {10.1017/9781108380690.001}
}

@article{Nian2020,
author = {Nian, Rui and Liu, Jinfeng and Huang, Biao},
year = {2020},
month = {04},
pages = {106886},
title = {A Review on Reinforcement Learning: Introduction and Applications in Industrial Process Control},
volume = {139},
journal = {Computers and Chemical Engineering},
doi = {10.1016/j.compchemeng.2020.106886}
}

@article{Montague1999,
author={Montague,P. R.},
year={1999},
title={Reinforcement Learning: An Introduction, by Sutton, R.S. and Barto, A.G},
journal={Trends in cognitive sciences},
volume={3},
number={9},
pages={360-360},
keywords={Computational learning; Dynamic programming; Reinforcement learning; Reward},
isbn={1364-6613},
language={English}
}

@article{silver2015,
author = {David Silver},
title = {Lectures on Reinforcement Learning},
url = {https://www.davidsilver.uk/teaching/},
year = {2015}
}

@electronic{MDEAI,
 title = {MDE Intelligence},
 url = {https://mde-intelligence.github.io/},
 urldate = {01.04.2022}
}

@inproceedings{Baier2019,
author = {Baier, Lucas and Jöhren, Fabian and Seebacher, Stefan},
year = {2019},
month = {05},
pages = {},
title = {CHALLENGES IN THE DEPLOYMENT AND OPERATION OF MACHINE LEARNING IN PRACTICE}
}

@book{Voelter2013,
  added-at = {2015-04-24T00:00:00.000+0200},
  author = {Voelter, Markus and Benz, Sebastian and Dietrich, Christian and Engelmann, Birgit and Helander, Mats and Kats, Lennart C. L. and Visser, Eelco and Wachsmuth, Guido},
  url = {https://www.bibsonomy.org/bibtex/2a0fb54f9c604aa9744fec956bfe43933/dblp},
  ee = {http://www.dslbook.org},
  interhash = {064b7593b436f5adf44878f605b4c1a6},
  intrahash = {a0fb54f9c604aa9744fec956bfe43933},
  isbn = {978-1-4812-1858-0},
  keywords = {dblp},
  pages = {1-558},
  publisher = {dslbook.org},
  timestamp = {2015-06-18T09:49:52.000+0200},
  title = {DSL Engineering - Designing, Implementing and Using Domain-Specific Languages.},
  year = 2013
}

@misc{tensorflow2015-whitepaper,
title={{TensorFlow}:Large-Scale Machine Learning on Heterogeneous Systems},
url = {https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015}
}

@article{Brambilla2017,
author = {Brambilla, Marco and Cabot, Jordi and Wimmer, Manuel},
year = {2017},
month = {03},
pages = {1-207},
title = {Model-Driven Software Engineering in Practice: Second Edition},
volume = {3},
journal = {Synthesis Lectures on Software Engineering},
doi = {10.2200/S00751ED2V01Y201701SWE004}
}

@article{Schmidt2006,
author = {Schmidt, Douglas},
year = {2006},
month = {01},
pages = {41-47},
title = {Model-driven engineering},
volume = {39},
journal = {IEEE Comput}
}

@misc{MPS,
title={MPS: The Domain-Specific Language Creator by JetBrains},
url = {https://www.jetbrains.com/mps/}
}

@misc{AutoML,
title={Automated machine learning (AutoML)},
url={https://www.automl.org/}
}

@inproceedings{Harrand2016,
author = {Harrand, Nicolas and Fleurey, Franck and Morin, Brice and Husa, Knut},
year = {2016},
month = {10},
pages = {125-135},
title = {ThingML: a language and code generation framework for heterogeneous targets},
doi = {10.1145/2976767.2976812}
}

@article{Zhao2017,
author = {Zhao, Tian and Huang, Xiaobing and Cao, Yu},
year = {2017},
month = {01},
pages = {},
title = {DeepDSL: A Compilation-based Domain-Specific Language for Deep Learning}
}

@misc{RL-coach,
title={Reinforcement Learning Coach RL-coach},
url={https://intellabs.github.io/coach/}
}

@book{Jiang2021,
author={Jiang,Hui (. s.},
year={2021},
title={Machine learning fundamentals: a concise introduction},
publisher={Cambridge University Press},
abstract={"This lucid, accessible introduction to supervised machine learning presents core concepts in a focused and logical way that is easy for beginners to follow. The author assumes basic calculus, linear algebra, probability and statistics but no prior exposure to machine learning. Coverage includes widely used traditional methods such as SVMs, boosted trees, HMMs, and LDAs, plus popular deep learning methods such as convolution neural nets, attention, transformers, and GANs. Organized in a coherent presentation framework that emphasizes the big picture, the text introduces each method clearly and concisely "from scratch" based on the fundamentals. All methods and algorithms are described by a clean and consistent style, with a minimum of unnecessary detail. Numerous case studies and concrete examples demonstrate how the methods can be applied in a variety of contexts. Hui Jiang is Professor of Electrical Engineering and Computer Science at York University, where he has been since 2002. His main research interests include machine learning, particularly deep learning, and its applications to speech and audio processing, natural language processing, and computer vision. Over the past 30 years, he has worked on a wide range of research problems from these areas and published hundreds of technical articles and papers in the mainstream journals and top-tier conferences. His works have won the prestigious IEEE Best Paper Award and the ACL Outstanding Paper honor"--},
keywords={Machine learning},
isbn={9781108938051;1108938051;},
language={English}
}

@misc{TRFL,
title={Deepmind TRFL},
url={https://www.deepmind.com/open-source/trfl}
}

@misc{TFAgents,
title={TensorFlow Agents (TF Agents)},
url={https://www.tensorflow.org/agents}
}

@book{Graesser2019,
author={Graesser,Laura and Keng,Wah and Safari, an O'Reilly Media Company},
year={2019},
title={Foundations of Deep Reinforcement Learning: Theory and Practice in Python},
publisher={Addison-Wesley Professional},
edition={1st},
abstract={The Contemporary Introduction to Deep Reinforcement Learning that Combines Theory and Practice Deep reinforcement learning (deep RL) combines deep learning and reinforcement learning, in which artificial agents learn to solve sequential decision-making problems. In the past decade deep RL has achieved remarkable results on a range of problems, from single and multiplayer games–such as Go, Atari games, and DotA 2–to robotics.Foundations of Deep Reinforcement Learning is an introduction to deep RL that uniquely combines both theory and implementation. It starts with intuition, then carefully explains the theory of deep RL algorithms, discusses implementations in its companion software library SLM Lab, and finishes with the practical details of getting deep RL to work.This guide is ideal for both computer science students and software engineers who are familiar with basic machine learning concepts and have a working understanding of Python.Understand each key aspect of a deep RL problemExplore policy- and value-based algorithms, including REINFORCE, SARSA, DQN, Double DQN, and Prioritized Experience Replay (PER)Delve into combined algorithms, including Actor-Critic and Proximal Policy Optimization (PPO)Understand how algorithms can be parallelized synchronously and asynchronouslyRun algorithms in SLM Lab and learn the practical implementation details for getting deep RL to workExplore algorithm benchmark results with tuned hyperparametersUnderstand how deep RL environments are designedRegister your book for convenient access to downloads, updates, and/or corrections as they become available. See inside book for details.;The Contemporary Introduction to Deep Reinforcement Learning that Combines Theory and Practice Deep reinforcement learning (deep RL) combines deep learning and reinforcement learning, in which artificial agents learn to solve sequential decision-making problems. In the past decade deep RL has achieved remarkable results on a range of problems, from single and multiplayer games-such as Go, Atari games, and DotA 2-to robotics. Foundations of Deep Reinforcement Learning is an introduction to deep RL that uniquely combines both theory and implementation. It starts with intuition, then carefully explains the theory of deep RL algorithms, discusses implementations in its companion software library SLM Lab, and finishes with the practical details of getting deep RL to work. This guide is ideal for both computer science students and software engineers who are familiar with basic machine learning concepts and have a working understanding of Python. Understand each key aspect of a deep RL problem Explore policy- and value-based algorithms, including REINFORCE, SARSA, DQN, Double DQN, and Prioritized Experience Replay (PER) Delve into combined algorithms, including Actor-Critic and Proximal Policy Optimization (PPO) Understand how algorithms can be parallelized synchronously and asynchronously Run algorithms in SLM Lab and learn the practical implementation details for getting deep RL to work Explore algorithm benchmark results with tuned hyperparameters Understand how deep RL environments are designed Register your book for convenient access to downloads, updates, and/or corrections as they become available. See inside book for details.;},
isbn={0135172497;9780135172490;},
language={English}
}

@article{Kahlaoui2008,
author = {Kahlaoui, Abdelilah and Abran, Alain and Lefebvre, Eric},
year = {2008},
month = {01},
pages = {},
title = {DSML Success Factors and Their Assessment Criteria},
volume = {13},
journal = {Metrics News}
}

@book{ Ravichandiran2018,
author={Ravichandiran,Sudharsan},
year={2018},
title={Hands-On Reinforcement Learning with Python: Master Reinforcement and Deep Reinforcement Learning Using OpenAI Gym and TensorFlow},
publisher={Packt Publishing, Limited},
address={Birmingham},
abstract={Reinforcement learning is a self-evolving type of machine learning that takes us closer to achieving true artificial intelligence. This easy-to-follow guide explains everything from scratch using rich examples written in Python.},
keywords={Machine learning},
isbn={9781788836524;1788836529;},
language={English}
}

@book{books/daglib/0030751,
  added-at = {2015-04-24T00:00:00.000+0200},
  author = {Voelter, Markus and Benz, Sebastian and Dietrich, Christian and Engelmann, Birgit and Helander, Mats and Kats, Lennart C. L. and Visser, Eelco and Wachsmuth, Guido},
  biburl = {https://www.bibsonomy.org/bibtex/2a0fb54f9c604aa9744fec956bfe43933/dblp},
  ee = {http://www.dslbook.org},
  interhash = {064b7593b436f5adf44878f605b4c1a6},
  intrahash = {a0fb54f9c604aa9744fec956bfe43933},
  isbn = {978-1-4812-1858-0},
  keywords = {dblp},
  pages = {1-558},
  publisher = {dslbook.org},
  timestamp = {2015-06-18T09:49:52.000+0200},
  title = {DSL Engineering - Designing, Implementing and Using Domain-Specific Languages.},
  year = 2013
}

@article{Verma2020,
author = {Verma, Pushpneel and Dhanre, Urvashi and Khekare, Seema and Sheikh, Shahrukh and Khekare, Ganesh},
year = {2020},
month = {09},
pages = {1-18},
title = {The Optimal Path Finding Algorithm Based on Reinforcement Learning},
volume = {12},
journal = {International Journal of Software Science and Computational Intelligence},
doi = {10.4018/IJSSCI.2020100101}
}

@misc{simpleGame,
title={Reinforcement Learning explained visually (A Simple game example))},
url={https://towardsdatascience.com/reinforcement-learning-explained-visually-part-4-q-learning-step-by-step-b65efb731d3e
}
}

@misc{Papyrus,
title={Eclipse Papyrus™},
url={https://projects.eclipse.org/projects/modeling.mdt.papyrus}
}

@misc{Xtext,
title={Xtext - LANGUAGE ENGINEERING FOR EVERYONE!},
url={https://www.eclipse.org/Xtext/}
}

@inproceedings{AToM3,
author = {Lara, Juan de and Vangheluwe, Hans},
title = {AToM3: A Tool for Multi-Formalism and Meta-Modelling},
year = {2002},
isbn = {3540433538},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {This article introduces the combined use of multiformalism modelling and meta-modelling to facilitate computer assisted modelling of complex systems. The approach allows one to model different parts of a system using different formalisms. Models can be automatically converted between formalisms thanks to information found in a Formalism Transformation Graph (FTG), proposed by the authors. To aid in the automatic generation of multi-formalism modelling tools, formalisms are modelled in their own right (at a meta-level) within an appropriate formalism. This has been implemented in the interactive tool AToM3. This tool is used to describe formalisms commonly used in the simulation of dynamical systems, as well as to generate custom tools to process (create, edit, transform, simulate, optimise, ...) models expressed in the corresponding formalism. AToM3 relies on graph rewriting techniques and graph grammars to perform the transformations between formalisms as well as for other tasks, such as code generation and operational semantics specification.},
booktitle = {Proceedings of the 5th International Conference on Fundamental Approaches to Software Engineering},
pages = {174–188},
numpages = {15},
keywords = {multi-formalism modeling, modeling and simulation, meta-modeling, graph grammars, automatic code generation},
series = {FASE '02}
}

@inproceedings{MetaEdit+,
author = {Tolvanen, Juha-Pekka and Kelly, Steven},
title = {MetaEdit+: Defining and Using Integrated Domain-Specific Modeling Languages},
year = {2009},
isbn = {9781605587684},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1639950.1640031},
doi = {10.1145/1639950.1640031},
abstract = {With MetaEdit+ you can build Domain-Specific Modeling languages and tools - without having to write a single line of code. This demonstration shows how different domain-specific languages (DSLs) can be integrated with high-level metamodels, how languages can be created iteratively while automatically updating existing models, and how multiple modelers can work together seamlessly.},
booktitle = {Proceedings of the 24th ACM SIGPLAN Conference Companion on Object Oriented Programming Systems Languages and Applications},
pages = {819–820},
numpages = {2},
keywords = {language workbench, domain-specific languages, domain-specific modeling, metamodeling, code generation},
location = {Orlando, Florida, USA},
series = {OOPSLA '09}
}

@misc{Demo,
title={RLML Demo},
author = {Natalie Sinani},
url={https://drive.google.com/drive/u/4/folders/1EfcsSdkBSkJyjPdlwhmGchnqZYYagpBA}
}
